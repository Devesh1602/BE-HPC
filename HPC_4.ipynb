{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8chric1KD5IG",
        "outputId": "36817cef-5b8a-4a89-9263-16ee4d644ef1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/afnan47/cuda.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bN7Q-D41D4eX",
        "outputId": "df5e62e1-001e-4b1f-aa4c-9c63943c754c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/afnan47/cuda.git\n",
            "  Cloning https://github.com/afnan47/cuda.git to /tmp/pip-req-build-kynjyicw\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/afnan47/cuda.git /tmp/pip-req-build-kynjyicw\n",
            "  Resolved https://github.com/afnan47/cuda.git to commit aac710a35f52bb78ab34d2e52517237941399eff\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4289 sha256=ac71525b44952bf0785ba3add5fe2cba1fdef0786381b825a0abb9df6dba99ac\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-65c3s0qq/wheels/aa/f3/44/e10c1d226ec561d971fcd4b0463f6bff08602afa928a3e7bc7\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6lINFEoD4Mo",
        "outputId": "9bde60c7-ac0e-43ac-b937-addf8fac9c14"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zb2ATDEgcBig",
        "outputId": "bedd54a0-4944-4a4e-82d2-35c9e314ce82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing add.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile add.cu\n",
        "#include <iostream>\n",
        "#include <cstdlib> // Include <cstdlib> for rand()\n",
        "using namespace std;\n",
        "\n",
        "__global__\n",
        "void add(int* A, int* B, int* C, int size) {\n",
        "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (tid < size) {\n",
        "        C[tid] = A[tid] + B[tid];\n",
        "    }\n",
        "}\n",
        "\n",
        "void print(int* vector, int size) {\n",
        "    for (int i = 0; i < size; i++) {\n",
        "        cout << vector[i] << \" \";\n",
        "    }\n",
        "    cout << endl;\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int N;\n",
        "    cout << \"Enter the size of the vectors: \";\n",
        "    cin >> N;\n",
        "\n",
        "    int* A, * B, * C;\n",
        "    int vectorSize = N;\n",
        "    size_t vectorBytes = vectorSize * sizeof(int);\n",
        "\n",
        "    // Allocate host memory\n",
        "    A = new int[vectorSize];\n",
        "    B = new int[vectorSize];\n",
        "    C = new int[vectorSize];\n",
        "\n",
        "    // Initialize host arrays\n",
        "    cout << \"Enter elements of vector A:\" << endl;\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        cin >> A[i];\n",
        "    }\n",
        "    cout << \"Enter elements of vector B:\" << endl;\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        cin >> B[i];\n",
        "    }\n",
        "    cout << \"Vector A: \";\n",
        "    print(A, N);\n",
        "    cout << \"Vector B: \";\n",
        "    print(B, N);\n",
        "\n",
        "    int* X, * Y, * Z;\n",
        "    // Allocate device memory\n",
        "    cudaMalloc(&X, vectorBytes);\n",
        "    cudaMalloc(&Y, vectorBytes);\n",
        "    cudaMalloc(&Z, vectorBytes);\n",
        "\n",
        "    // Check for CUDA memory allocation errors\n",
        "    if (X == nullptr || Y == nullptr || Z == nullptr) {\n",
        "        cerr << \"CUDA memory allocation failed\" << endl;\n",
        "        return 1;\n",
        "    }\n",
        "\n",
        "    // Copy data from host to device\n",
        "    cudaMemcpy(X, A, vectorBytes, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(Y, B, vectorBytes, cudaMemcpyHostToDevice);\n",
        "\n",
        "    int threadsPerBlock = 256;\n",
        "    int blocksPerGrid = (N + threadsPerBlock - 1) / threadsPerBlock;\n",
        "\n",
        "    // Launch kernel\n",
        "    add<<<blocksPerGrid, threadsPerBlock>>>(X, Y, Z, N);\n",
        "\n",
        "    // Check for kernel launch errors\n",
        "    cudaError_t kernelLaunchError = cudaGetLastError();\n",
        "    if (kernelLaunchError != cudaSuccess) {\n",
        "        cerr << \"CUDA kernel launch failed: \" << cudaGetErrorString(kernelLaunchError) << endl;\n",
        "        return 1;\n",
        "    }\n",
        "\n",
        "    // Copy result from device to host\n",
        "    cudaMemcpy(C, Z, vectorBytes, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Check for CUDA memcpy errors\n",
        "    cudaError_t memcpyError = cudaGetLastError();\n",
        "    if (memcpyError != cudaSuccess) {\n",
        "        cerr << \"CUDA memcpy failed: \" << cudaGetErrorString(memcpyError) << endl;\n",
        "        return 1;\n",
        "    }\n",
        "\n",
        "    cout << \"Addition: \";\n",
        "    print(C, N);\n",
        "\n",
        "    // Free device memory\n",
        "    cudaFree(X);\n",
        "    cudaFree(Y);\n",
        "    cudaFree(Z);\n",
        "\n",
        "    // Free host memory\n",
        "    delete[] A;\n",
        "    delete[] B;\n",
        "    delete[] C;\n",
        "\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rMTP2bOmD2n8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc add.cu -o add\n",
        "!./add"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2B8G2NxcnBm",
        "outputId": "dffb29c3-b8fa-4d38-b6e6-df5ea317cd55"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the size of the vectors: 3\n",
            "Enter elements of vector A:\n",
            "1\n",
            "2\n",
            "3\n",
            "Enter elements of vector B:\n",
            "3\n",
            "2\n",
            "1\n",
            "Vector A: 1 2 3 \n",
            "Vector B: 3 2 1 \n",
            "Addition: 4 4 4 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fOFig6uvD0Ug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile matrix_mult.cu\n",
        "#include <iostream>\n",
        "#include <cuda.h>\n",
        "using namespace std;\n",
        "\n",
        "#define BLOCK_SIZE 1\n",
        "\n",
        "__global__ void gpuMM(float *A, float *B, float *C, int N) {\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    float sum = 0.f;\n",
        "    for (int n = 0; n < N; ++n)\n",
        "        sum += A[row * N + n] * B[n * N + col];\n",
        "    C[row * N + col] = sum;\n",
        "}\n",
        "\n",
        "int main(int argc, char *argv[]) {\n",
        "    int N;\n",
        "\n",
        "    // Get matrix size from user\n",
        "    cout << \"Enter size of matrix (N): \";\n",
        "    cin >> N;\n",
        "    if (N % BLOCK_SIZE != 0) {\n",
        "        cerr << \"Matrix size must be a multiple of BLOCK_SIZE.\" << endl;\n",
        "        return 1;\n",
        "    }\n",
        "\n",
        "    cout << \"\\nExecuting Matrix Multiplication\" << endl;\n",
        "    cout << \"Matrix size: \" << N << \"x\" << N << endl;\n",
        "\n",
        "    // Allocate memory for matrices on the host\n",
        "    float *hA, *hB, *hC;\n",
        "    hA = new float[N * N];\n",
        "    hB = new float[N * N];\n",
        "    hC = new float[N * N];\n",
        "\n",
        "    // Read matrices from user\n",
        "    cout << \"Enter elements of matrix A (\" << N << \"x\" << N << \"):\" << endl;\n",
        "    for (int i = 0; i < N * N; ++i)\n",
        "        cin >> hA[i];\n",
        "\n",
        "    cout << \"Enter elements of matrix B (\" << N << \"x\" << N << \"):\" << endl;\n",
        "    for (int i = 0; i < N * N; ++i)\n",
        "        cin >> hB[i];\n",
        "\n",
        "    // Allocate memory for matrices on the device\n",
        "    int size = N * N * sizeof(float);\n",
        "    float *dA, *dB, *dC;\n",
        "    cudaMalloc(&dA, size);\n",
        "    cudaMalloc(&dB, size);\n",
        "    cudaMalloc(&dC, size);\n",
        "\n",
        "    // Copy matrices from the host to the device\n",
        "    cudaMemcpy(dA, hA, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(dB, hB, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    dim3 threadBlock(BLOCK_SIZE, BLOCK_SIZE);\n",
        "    dim3 grid(N / BLOCK_SIZE, N / BLOCK_SIZE);\n",
        "\n",
        "    // Execute the matrix multiplication kernel\n",
        "    gpuMM<<<grid, threadBlock>>>(dA, dB, dC, N);\n",
        "\n",
        "    // Copy the result matrix from the device to the host\n",
        "    cudaMemcpy(hC, dC, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Display the result matrix\n",
        "    cout << \"\\nResultant matrix:\\n\";\n",
        "    for (int row = 0; row < N; row++) {\n",
        "        for (int col = 0; col < N; col++) {\n",
        "            cout << hC[row * N + col] << \" \";\n",
        "        }\n",
        "        cout << endl;\n",
        "    }\n",
        "\n",
        "    // Free device memory\n",
        "    cudaFree(dA);\n",
        "    cudaFree(dB);\n",
        "    cudaFree(dC);\n",
        "\n",
        "    // Free host memory\n",
        "    delete[] hA;\n",
        "    delete[] hB;\n",
        "    delete[] hC;\n",
        "\n",
        "    cout << \"Finished.\" << endl;\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jn7z-1Tgc0Du",
        "outputId": "f6842845-ca6d-40b7-bb49-c9aa4f99bc03"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting matrix_mult.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc matrix_mult.cu -o matrix_mult\n",
        "!./matrix_mult"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BaSXn67DdqL9",
        "outputId": "a524093a-21e1-4f4b-e288-2c0ee554d408"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter size of matrix (N): 3\n",
            "\n",
            "Executing Matrix Multiplication\n",
            "Matrix size: 3x3\n",
            "Enter elements of matrix A (3x3):\n",
            "1\n",
            "2\n",
            "3\n",
            "6\n",
            "5\n",
            "4\n",
            "7\n",
            "8\n",
            "9\n",
            "Enter elements of matrix B (3x3):\n",
            "9\n",
            "8\n",
            "7\n",
            "6\n",
            "5\n",
            "4\n",
            "3\n",
            "2\n",
            "1\n",
            "\n",
            "Resultant matrix:\n",
            "30 24 18 \n",
            "96 81 66 \n",
            "138 114 90 \n",
            "Finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8CdN3XQfdxJA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}